{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "def load_config(yaml_file):\n",
    "    with open(yaml_file, \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "config = load_config(\"config.yaml\")\n",
    "\n",
    "cuda_devices = config[\"cuda\"][\"devices\"]\n",
    "# data\n",
    "data_dir = config[\"data\"]\n",
    "# model\n",
    "model_name = config[\"model\"][\"name\"]\n",
    "#lora\n",
    "rank = int(config[\"lora\"][\"rank\"])\n",
    "alpha = int(config[\"lora\"][\"alpha\"])\n",
    "\n",
    "# training\n",
    "max_seq_length = config[\"training\"][\"max_seq_length\"]\n",
    "learning_rate = float(config[\"training\"][\"learning_rate\"])\n",
    "train_epochs = config[\"training\"][\"train_epochs\"]\n",
    "per_device_batch_size = config[\"training\"][\"per_device_batch_size\"]\n",
    "gradient_accumulation_steps = config[\"training\"][\"gradient_accumulation_steps\"]\n",
    "save_steps = config[\"training\"][\"save_steps\"]\n",
    "eval_steps = config[\"training\"][\"eval_steps\"]\n",
    "logging_steps = config[\"training\"][\"logging_steps\"]\n",
    "random_seed = config[\"training\"][\"random_seed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set the cuda device(s)\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = cuda_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load libraries and model from HF \n",
    "import torch\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import wandb\n",
    "from trl import SFTTrainer, SFTConfig, DataCollatorForCompletionOnlyLM # to train model only on the generated prompts\n",
    "#from trl.trainer import ConstantLengthDataset\n",
    "from datasets import load_dataset\n",
    "from _1_prompt_temp_v1 import instruction_format, conversational_format, sys_prompt\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported, apply_chat_template\n",
    "\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d%H%M\")\n",
    "# Initialize WandB (ensure you've logged in using `wandb login`)\n",
    "wandb.init(project=\"code-llama-finetuning\", \n",
    "           name=f\"fine-tune-{model_name.split('/')[-1]}-{data_dir.split('/')[-1]}_{timestamp}\",\n",
    "           config={\"learning_rate\": learning_rate, \"num_train_epochs\": train_epochs, \"max_seq_length\": max_seq_length, \"learning_rate\": learning_rate})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name,\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=True,\n",
    "    dtype=None,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=rank,\n",
    "    lora_alpha=alpha,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"], \n",
    "    use_rslora=True,\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state= random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(data_dir)\n",
    "\n",
    "for split in dataset:\n",
    "    dataset[split] = dataset[split].map(lambda x: instruction_format(x, include_description=True, include_ascii=True))\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = dataset[\"train\"], dataset[\"validation\"], dataset[\"test\"]\n",
    "\n",
    "# Print out a sample to confirm the changes\n",
    "print(train_dataset[\"conversations\"][0])\n",
    "\n",
    "### define and apply chat template\n",
    "chat_template = \"\"\"### Instruction:\n",
    "{INPUT}\n",
    "### Python Program:\n",
    "{OUTPUT}\"\"\"\n",
    "\n",
    "dataset = apply_chat_template(\n",
    "    dataset,\n",
    "    tokenizer = tokenizer,\n",
    "    chat_template = chat_template,\n",
    "    default_system_message = sys_prompt, # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_1 = SFTTrainer(\n",
    "    model,\n",
    "    tokenizer=tokenizer,            # tokenizer or collator (bc collator \n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=None, # (Callable[[transformers.EvalPrediction], dict], optional defaults to None) — The function used to compute metrics during evaluation. It should return a dictionary mapping metric names to metric values. If not specified, only the loss will be computed during evaluation.\n",
    "    args = SFTConfig(\n",
    "        output_dir = f\"./results/fine-tune-{model_name.split('/')[-1]}-{data_dir.split('/')[-1]}_{timestamp}\",\n",
    "        # pre-processing\n",
    "        max_seq_length = max_seq_length,\n",
    "        packing = False,\n",
    "        dataset_num_proc =4,\n",
    "        # training parameters\n",
    "        learning_rate = learning_rate,\n",
    "        num_train_epochs = train_epochs,\n",
    "        gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "        per_device_train_batch_size = per_device_batch_size,\n",
    "        per_device_eval_batch_size = per_device_batch_size,\n",
    "        # reporting and logging\n",
    "        report_to = [\"wandb\"],\n",
    "        push_to_hub = True,\n",
    "        hub_model_id = f\"fine-tune-{model_name.split('/')[-1]}-{data_dir.split('/')[-1]}_{timestamp}\",\n",
    "        logging_strategy = \"steps\",\n",
    "        logging_steps = logging_steps,\n",
    "        # checkpointing\n",
    "        save_strategy = \"steps\",\n",
    "        save_steps = save_steps,\n",
    "        # evaluation\n",
    "        eval_strategy = \"steps\",\n",
    "        eval_steps = eval_steps,\n",
    "        # optimization\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),    \n",
    "        # ensure reproducibility\n",
    "        seed = random_seed,\n",
    "        data_seed = random_seed,\n",
    "        full_determinism=True\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on completions only ###\n",
    "https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only\n",
    "\n",
    "orients on the instruction_format_v1 function from _1_prompt_temp_v2.py but excludes the include_description and include_ascii arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example[\"Description\"])):\n",
    "        formated_input = f\"Generate a python program producing the graphic, which is described and depicted as follows:\\n    The Program draws {example['Description'][i]}\\n    Graphic:\\n{example['ASCII-Art'][i]}\\n\"\n",
    "        text = f\"### Instruction: {formated_input}\\n### Python Program: {example['Program'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "\n",
    "response_template = \"### Python Program:\" \n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "\n",
    "trainer_2 = SFTTrainer(\n",
    "    model,\n",
    "    data_collator=collator,          \n",
    "    formatting_func=formatting_prompts_func, \n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=None, # (Callable[[transformers.EvalPrediction], dict], optional defaults to None) — The function used to compute metrics during evaluation. It should return a dictionary mapping metric names to metric values. If not specified, only the loss will be computed during evaluation.\n",
    "    args = SFTConfig(\n",
    "        output_dir = f\"./results/fine-tune-{model_name.split('/')[-1]}-{data_dir.split('/')[-1]}_{timestamp}\",\n",
    "        # pre-processing\n",
    "        max_seq_length = max_seq_length,\n",
    "        packing = False,\n",
    "        dataset_num_proc =4,\n",
    "        # training parameters\n",
    "        learning_rate = learning_rate,\n",
    "        num_train_epochs = train_epochs,\n",
    "        gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "        per_device_train_batch_size = per_device_batch_size,\n",
    "        per_device_eval_batch_size = per_device_batch_size,\n",
    "        # reporting and logging\n",
    "        report_to = [\"wandb\"],\n",
    "        push_to_hub = True,\n",
    "        hub_model_id = f\"fine-tune-{model_name.split('/')[-1]}-{data_dir.split('/')[-1]}_{timestamp}\",\n",
    "        logging_strategy = \"steps\",\n",
    "        logging_steps = logging_steps,\n",
    "        # checkpointing\n",
    "        save_strategy = \"steps\",\n",
    "        save_steps = save_steps,\n",
    "        # evaluation\n",
    "        eval_strategy = \"steps\",\n",
    "        eval_steps = eval_steps,\n",
    "        # optimization\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),    \n",
    "        # ensure reproducibility\n",
    "        seed = random_seed,\n",
    "        data_seed = random_seed,\n",
    "        full_determinism=True\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"training\"][\"trainer_output_only\"]:\n",
    "    trainer_2.train()\n",
    "else:\n",
    "    trainer_1.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReGAL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
