==((====))==  Unsloth 2024.12.4: Fast Llama patching. Transformers:4.46.3.
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.529 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1. CUDA: 8.6. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth 2024.12.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
Map (num_proc=4): 100%|█████████████████████████████████████████████████████████████████████████| 8006/8006 [00:03<00:00, 2655.92 examples/s]
Map (num_proc=4): 100%|███████████████████████████████████████████████████████████████████████████| 997/997 [00:00<00:00, 1859.45 examples/s]
Map (num_proc=4): 100%|███████████████████████████████████████████████████████████████████████████| 997/997 [00:00<00:00, 1819.74 examples/s]
Traceback (most recent call last):
  File "/ceph/pratz/GitHub_repos/master-thesis/finetuning_expt2.py", line 70, in <module>
    training_args = TrainingArguments(
TypeError: TrainingArguments.__init__() got an unexpected keyword argument 'max_new_tokens'
Traceback (most recent call last):
  File "/ceph/pratz/GitHub_repos/master-thesis/finetuning_expt2.py", line 70, in <module>
    training_args = TrainingArguments(
TypeError: TrainingArguments.__init__() got an unexpected keyword argument 'max_new_tokens'
