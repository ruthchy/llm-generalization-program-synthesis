hyperparameter_grid:
  learning_rate: [2e-4, 1e-4, 2e-5]
  learning_rate_scheduler: ["linear", "cosine"]
  per_device_train_batch_size: [8, 16]
  lora_rank: [128, 512]
  lora_alpha: [128, 512]

# Track which combinations have been run
experiments_log: "hp_experiments_log.json"
current_run: 0