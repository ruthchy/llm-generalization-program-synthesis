data:
  ascii_parameters:
    black_threshold: 200
    block_size: 32
    crop_to_size: 512
  dataset_id: ruthchy/length-gen-logo-image
  image_to_ascii: true
  include_ascii: true
  include_desc: false
  include_sys_prompt_fn: false
  include_sys_prompt_inf: true
  mix_directions: false
  use_forkstate: false
logging:
  use_wandb: true
lora:
  alpha: 128
  dropout: 0
  rank: 64
  target_modules:
  - q_proj
  - k_proj
  - v_proj
  - up_proj
  - down_proj
  - o_proj
  - gate_proj
model:
  max_new_tokens: 250
  model_id: codellama/CodeLlama-7b-Instruct-hf
  num_return_sequences: 10
  temperature: 1.0
  top_k: 50
  topk_prompt: 0
  topk_train: 1
training:
  eval_steps: 100
  gradient_accumulation_steps: 4
  learning_rate: 2e-4
  logging_steps: 5
  lr_scheduler_type: linear
  max_seq_length: 4096
  per_device_eval_batch_size: 32
  per_device_train_batch_size: 8
  prompt_loss_weight: 0.5
  random_seed: 42
  save_steps: 500
  shuffle: true
  train_epochs: 1
  warmup_ratio: 0.0
  warmup_steps: null
