{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Synthetic Data with LOGO-Programs, Descriptions and the respective Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "from _1_logo_pseudo_code_generator import generateLOGOPseudoCode\n",
    "from _2_sampler import LOGOProgramSampler\n",
    "from _3_executable_logo_primitives import ReGALLOGOPrimitives\n",
    "from _4_logo_graphic_generator_v1 import PseudoProgramInterpreter as PseudoProgramInterpreter_v1\n",
    "from _4_logo_graphic_generator_v2 import PseudoProgramInterpreter as PseudoProgramInterpreter_v2\n",
    "from _5_ascii_processor import ASCIIProcessor\n",
    "\n",
    "generator=generateLOGOPseudoCode()\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the train and test data from the ReGAL-Paper. Join both and remove duplicate programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>8 sided snowflake with a short space and a sho...</td>\n",
       "      <td>for j in range(8):\\n    embed(\"\"\"penup()\\nforw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>8 sided snowflake with a medium triangle as arms</td>\n",
       "      <td>for j in range(8):\\n    embed(\"\"\"for i in rang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description  \\\n",
       "198  8 sided snowflake with a short space and a sho...   \n",
       "199   8 sided snowflake with a medium triangle as arms   \n",
       "\n",
       "                                               Program  \n",
       "198  for j in range(8):\\n    embed(\"\"\"penup()\\nforw...  \n",
       "199  for j in range(8):\\n    embed(\"\"\"for i in rang...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5 sided snowflake with a short line and a smal...</td>\n",
       "      <td>for j in range(5):\\n    embed(\"\"\"forward(4)\\nl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6 sided snowflake with a short space and a sho...</td>\n",
       "      <td>for j in range(6):\\n    embed(\"\"\"penup()\\nforw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Description  \\\n",
       "98  5 sided snowflake with a short line and a smal...   \n",
       "99  6 sided snowflake with a short space and a sho...   \n",
       "\n",
       "                                              Program  \n",
       "98  for j in range(5):\\n    embed(\"\"\"forward(4)\\nl...  \n",
       "99  for j in range(6):\\n    embed(\"\"\"penup()\\nforw...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>5 sided snowflake with a small 5 gon and a sma...</td>\n",
       "      <td>for j in range(5):\\n    embed(\"\"\"penup()\\nforw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6 sided snowflake with a small 5 gon and a sma...</td>\n",
       "      <td>for j in range(6):\\n    embed(\"\"\"penup()\\nforw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description  \\\n",
       "109  5 sided snowflake with a small 5 gon and a sma...   \n",
       "110  6 sided snowflake with a small 5 gon and a sma...   \n",
       "\n",
       "                                               Program  \n",
       "109  for j in range(5):\\n    embed(\"\"\"penup()\\nforw...  \n",
       "110  for j in range(6):\\n    embed(\"\"\"penup()\\nforw...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LOGO\n",
    "train_logo_data = \"logo_data/python/train_200_dataset.jsonl\"\n",
    "dev_logo_data = \"logo_data/python/dev_100.jsonl\"\n",
    "test_logo_data = \"logo_data/python/test_dataset.jsonl\"\n",
    "\n",
    "# Load train, dev and test dataset\n",
    "def load_data(data_path):\n",
    "    with open(data_path, 'r') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    return data\n",
    "\n",
    "# Extract descriptions and programs from train_data and transform into pandas DataFrame\n",
    "def extract_descriptions_and_programs(data):\n",
    "    extracted_data = []\n",
    "    for item in data:\n",
    "        description = None\n",
    "        program = None\n",
    "        if \"messages\" in item:  # suits the format for train_data and test_data\n",
    "            for message in item.get('messages', []):\n",
    "                if message['from'] == 'human':\n",
    "                    description = message['value']\n",
    "                elif message['from'] == 'gpt':\n",
    "                    program = message['value']\n",
    "        elif \"program\" in item and \"language\" in item: # suites the format for dev_data\n",
    "            program = item['program']\n",
    "            description = \" \".join(item['language'])\n",
    "\n",
    "        if description and program:\n",
    "            extracted_data.append([description, program])\n",
    "    extracted_data = pd.DataFrame(extracted_data, columns=['Description', 'Program'])\n",
    "    return extracted_data\n",
    "\n",
    "df_train = extract_descriptions_and_programs(load_data(f\"../external/dependencies/{train_logo_data}\"))\n",
    "df_dev = extract_descriptions_and_programs(load_data(f\"../external/dependencies/{dev_logo_data}\"))\n",
    "df_test = extract_descriptions_and_programs(load_data(f\"../external/dependencies/{test_logo_data}\"))\n",
    "\n",
    "display(df_train.tail(2))\n",
    "display(df_dev.tail(2))\n",
    "display(df_test.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the combined train and test data:  (311, 2)\n",
      "Dimensions of the combined train, dev and test data:  (411, 2)\n",
      "\n",
      "\n",
      "Dimensions of the combined train and test data without duplicate Programs:  (263, 2)\n",
      "Dimensions of the combined train, dev and test data without duplicate Programs:  (357, 2)\n"
     ]
    }
   ],
   "source": [
    "# Append the test data to the train data\n",
    "df_train_test = pd.concat([df_train, df_test], ignore_index=True)\n",
    "df_all = pd.concat([df_train, df_dev, df_test], ignore_index=True)\n",
    "print(\"Dimensions of the combined train and test data: \", df_train_test.shape)\n",
    "print(\"Dimensions of the combined train, dev and test data: \", df_all.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "#####################\n",
    "# Drop all duplicate rows\n",
    "df_train_test = df_train_test.drop_duplicates(subset=['Program']) # use the program as the unique identifier\n",
    "df_all = df_all.drop_duplicates(subset=['Program']) # use the program as the unique identifier\n",
    "#####################\n",
    "print(\"Dimensions of the combined train and test data without duplicate Programs: \", df_train_test.shape)\n",
    "print(\"Dimensions of the combined train, dev and test data without duplicate Programs: \", df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "54\n",
      "9643\n"
     ]
    }
   ],
   "source": [
    "print(311-263)\n",
    "print(411-357)\n",
    "print(10000-357)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Graphics for the ReGAL dataset and the Synthetic Data\n",
    "\n",
    "- initialize the sampler, if the train and test dataframes are porvided then the newly generated programs are not the same as the once in these datasets\n",
    "- the data can be stored in json-line format\n",
    "- next step is to initalize the interpreter, with this one can execute the programs and generate graphs\n",
    "    - the interpreter generates .png-files\n",
    "    - the size is for all graphics in one df the same (the aim is to keep size information which is relative to the other graphics thats why there can be a lot of whitespace this might be debatable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler=LOGOProgramSampler(generator, df_all) # this way only new programs are generated that are not in the train or test data\n",
    "\n",
    "# Synthetic data\n",
    "#synthetic_data = sampler.sample(9643) # sample 9643 new programs + the 357 programs from the train, dev and test data = 10000 programs\n",
    "#synthetic_data = pd.DataFrame(synthetic_data, columns=['Description', 'Program'])\n",
    "\n",
    "#save data as json-line file with current timestamp\n",
    "#timestamp = pd.Timestamp.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "#synthetic_data.to_json(f\"data/synthetic_data_{timestamp}.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "# load synthetic data\n",
    "synthetic_data = pd.read_json(\"data/synthetic_data_20250120143151.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate graphics for the synthetic data \n",
    "interpreter = PseudoProgramInterpreter_v2()\n",
    "interpreter.process_and_save_graphics(synthetic_data, output_dir=\"logo_graphic/synthetic_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = PseudoProgramInterpreter_v1()\n",
    "interpreter.process_and_save_graphics(synthetic_data, output_dir=\"logo_graphic/synthetic_v1\") # here graphics are thigthly cropped around the image\n",
    "# ca. 10.000 = 30 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 medium line in a row\n",
      "for j in range(7):\n",
      "    embed(\"\"\"forward(4)\"\"\", locals())\n",
      "    penup()\n",
      "    forward(2)\n",
      "    left(0.0)\n",
      "\n",
      "    pendown()\n",
      "connected sequence of shapes: a small 6-gon, a short line, a small 9-gon\n",
      "for i in range(6):\n",
      "    forward(2)\n",
      "    left(60.0)\n",
      "forward(2)\n",
      "for i in range(9):\n",
      "    forward(2)\n",
      "    left(40.0)\n"
     ]
    }
   ],
   "source": [
    "print(synthetic_data['Description'].iloc[4])\n",
    "print(synthetic_data['Program'].iloc[4])\n",
    "\n",
    "print(synthetic_data['Description'].iloc[9])\n",
    "print(synthetic_data['Program'].iloc[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST \n",
    "# create a test dataset form the all_data\n",
    "test_indices = [98, 44, 100, 99, 200, 212, 214, 201, 53, 54, 282] # examples representing different shapes and combinations for testing purposes\n",
    "df_test_subset = df_all.loc[test_indices].reset_index(drop=True)\n",
    "#display(df_test_subset)\n",
    "\n",
    "interpreter = PseudoProgramInterpreter_v2()\n",
    "interpreter.process_and_save_graphics(df_test_subset, output_dir=\"logo_graphic/11testshapes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReGAL DATA GRAPHICS\n",
    "interpreter = PseudoProgramInterpreter_v1()\n",
    "interpreter.process_and_save_graphics(df_all, output_dir=\"logo_graphic/all_ReGAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASCII-Transfromer\n",
    "\n",
    "based on the approach by Li and Ellis (2024). Similar to the authors  ensure a square image size (here 525x525) which I divied in 35x35 blocks with a pixel size of 15x15. In comparison the authors cropped a 512x512 section from the image around the center and divide it into 32x32 blocks with a pixel size of 16x16 each. Like the authors i then calculate the densty of black pixels and qunatizise this into 10 levels, which are represented by the ASCII numbers of 0-9. Each number represents a block resulting in a string with 35 lines, where each line has 35 numbers. A low density equals 0 and the higher the density of black pixels becomes the closer to 9 it will be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "      <th>ascii_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>separated sequence of shapes: a small 8-gon, a...</td>\n",
       "      <td>for i in range(8):\\n    forward(2)\\n    left(4...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a zigzag with 4 medium steps</td>\n",
       "      <td>for i in range(4):\\n    forward(4)\\n    left(9...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0  separated sequence of shapes: a small 8-gon, a...   \n",
       "1                       a zigzag with 4 medium steps   \n",
       "\n",
       "                                             Program  \\\n",
       "0  for i in range(8):\\n    forward(2)\\n    left(4...   \n",
       "1  for i in range(4):\\n    forward(4)\\n    left(9...   \n",
       "\n",
       "                                         ascii_input  \n",
       "0  00000000000000000000000000000000000\\n000000000...  \n",
       "1  00000000000000000000000000000000000\\n000000000...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Synthetic data ASCII\n",
    "processor = ASCIIProcessor(n_blocks=35, m_blocks=35, levels=10)\n",
    "\n",
    "dir_images = \"logo_graphic/synthetic_v1/\"\n",
    "synthetic_data_ascii = processor.store_ascii_input(synthetic_data, dir_images)\n",
    "display(synthetic_data_ascii.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "      <th>ascii_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 concentric square s</td>\n",
       "      <td>for i in range(5):\\n    embed(\"\"\"for j in rang...</td>\n",
       "      <td>00000000000000000000000000000000000\\n012222222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 sided snowflake with a medium line and a med...</td>\n",
       "      <td>for j in range(6):\\n    embed(\"\"\"forward(8)\\nl...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0                              4 concentric square s   \n",
       "1  6 sided snowflake with a medium line and a med...   \n",
       "\n",
       "                                             Program  \\\n",
       "0  for i in range(5):\\n    embed(\"\"\"for j in rang...   \n",
       "1  for j in range(6):\\n    embed(\"\"\"forward(8)\\nl...   \n",
       "\n",
       "                                         ascii_input  \n",
       "0  00000000000000000000000000000000000\\n012222222...  \n",
       "1  00000000000000000000000000000000000\\n000000000...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_images = \"logo_graphic/all_ReGAL/\"\n",
    "df_all_ascii = processor.store_ascii_input(df_all, dir_images)\n",
    "display(df_all_ascii.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Splits in Train and Test given generalization aspect\n",
    "\n",
    "- length generalization:\n",
    "    - criterion: semantic length\n",
    "- mix and match concepts\n",
    "    - compose different concepts\n",
    "    - switch concept order\n",
    "- apply general principles\n",
    "    - compose new operations\n",
    "    - add operation functunality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_syn = pd.concat([df_all_ascii, synthetic_data_ascii], ignore_index=True)\n",
    "len(df_all_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "9003\n",
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "      <th>ascii_input</th>\n",
       "      <th>Semantic Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a 5 pointed star</td>\n",
       "      <td>for i in range(5):\\n    forward(16)\\n    left(...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a greek spiral with 5 turns</td>\n",
       "      <td>for i in range(6):\\n    forward(1 * i)\\n    le...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Description  \\\n",
       "0             a 5 pointed star   \n",
       "1  a greek spiral with 5 turns   \n",
       "\n",
       "                                             Program  \\\n",
       "0  for i in range(5):\\n    forward(16)\\n    left(...   \n",
       "1  for i in range(6):\\n    forward(1 * i)\\n    le...   \n",
       "\n",
       "                                         ascii_input  Semantic Length  \n",
       "0  00000000000000000000000000000000000\\n000000000...                5  \n",
       "1  00000000000000000000000000000000000\\n000000000...                6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "      <th>ascii_input</th>\n",
       "      <th>Semantic Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9001</th>\n",
       "      <td>separated sequence of shapes: a small 7-gon, a...</td>\n",
       "      <td>for i in range(7):\\n    forward(2)\\n    left(5...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>1363362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9002</th>\n",
       "      <td>separated sequence of shapes: a small 7-gon, a...</td>\n",
       "      <td>for i in range(7):\\n    forward(2)\\n    left(5...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>1363362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Description  \\\n",
       "9001  separated sequence of shapes: a small 7-gon, a...   \n",
       "9002  separated sequence of shapes: a small 7-gon, a...   \n",
       "\n",
       "                                                Program  \\\n",
       "9001  for i in range(7):\\n    forward(2)\\n    left(5...   \n",
       "9002  for i in range(7):\\n    forward(2)\\n    left(5...   \n",
       "\n",
       "                                            ascii_input  Semantic Length  \n",
       "9001  00000000000000000000000000000000000\\n000000000...          1363362  \n",
       "9002  00000000000000000000000000000000000\\n000000000...          1363362  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "      <th>ascii_input</th>\n",
       "      <th>Semantic Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9003</th>\n",
       "      <td>a 3 sided snowflake with arms of connected seq...</td>\n",
       "      <td>for j in range(3):\\n    embed(\"\"\"for i in rang...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>1368450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9004</th>\n",
       "      <td>connected sequence of shapes: a small 7-gon, a...</td>\n",
       "      <td>for i in range(7):\\n    forward(2)\\n    left(5...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>1368451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Description  \\\n",
       "9003  a 3 sided snowflake with arms of connected seq...   \n",
       "9004  connected sequence of shapes: a small 7-gon, a...   \n",
       "\n",
       "                                                Program  \\\n",
       "9003  for j in range(3):\\n    embed(\"\"\"for i in rang...   \n",
       "9004  for i in range(7):\\n    forward(2)\\n    left(5...   \n",
       "\n",
       "                                            ascii_input  Semantic Length  \n",
       "9003  00000000000000000000000000000000000\\n000000000...          1368450  \n",
       "9004  00000000000000000000000000000000000\\n000000000...          1368451  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "      <th>ascii_input</th>\n",
       "      <th>Semantic Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>separated sequence of shapes: a small circle, ...</td>\n",
       "      <td>for i in range(HALF_INF):\\n    forward(EPS_DIS...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>68407622226360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>separated sequence of shapes: a small circle, ...</td>\n",
       "      <td>for i in range(HALF_INF):\\n    forward(EPS_DIS...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>68408672018760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Description  \\\n",
       "9998  separated sequence of shapes: a small circle, ...   \n",
       "9999  separated sequence of shapes: a small circle, ...   \n",
       "\n",
       "                                                Program  \\\n",
       "9998  for i in range(HALF_INF):\\n    forward(EPS_DIS...   \n",
       "9999  for i in range(HALF_INF):\\n    forward(EPS_DIS...   \n",
       "\n",
       "                                            ascii_input  Semantic Length  \n",
       "9998  00000000000000000000000000000000000\\n000000000...   68407622226360  \n",
       "9999  00000000000000000000000000000000000\\n000000000...   68408672018760  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set size: 8006\n",
      "\n",
      "Validation set size: 997\n",
      "\n",
      "Test set size: 997\n"
     ]
    }
   ],
   "source": [
    "from _6_semantic_length import SemanticLength\n",
    "\n",
    "sem_length = SemanticLength()\n",
    "\n",
    "df_all_syn['Semantic Length'] = df_all_syn['Program'].apply(sem_length.calc_semantic_length)\n",
    "df_all_syn=df_all_syn.sort_values(by=\"Semantic Length\").reset_index(drop=True)\n",
    "\n",
    "# Determine the split index\n",
    "test_start_id = int(len(df_all_syn)*0.9)        # 10% for the test set\n",
    "print(test_start_id)\n",
    "# check and adjust the split index if both train and test contain programs with the same semantic length\n",
    "while (\n",
    "    test_start_id < len(df_all_syn) and \n",
    "    df_all_syn.loc[test_start_id, 'Semantic Length'] == df_all_syn.loc[test_start_id - 1, 'Semantic Length']\n",
    "):\n",
    "    test_start_id += 1\n",
    "print(test_start_id)\n",
    "\n",
    "# Create train and test splits\n",
    "train_data = df_all_syn.iloc[:test_start_id]\n",
    "test_data = df_all_syn.iloc[test_start_id:]\n",
    "\n",
    "print(\"Train:\")\n",
    "display(train_data.head(2))\n",
    "display(train_data.tail(2))\n",
    "print(\"\\nTest:\")\n",
    "display(test_data.head(2))\n",
    "display(test_data.tail(2))\n",
    "\n",
    "# Create a validation dataset from the training data about the same size as the test data\n",
    "rs = 42\n",
    "length = int(len(test_data))\n",
    "validation_data = train_data.sample(n=length, random_state=rs)  \n",
    "train_data = train_data.drop(validation_data.index)\n",
    "\n",
    "print(\"\\nTrain set size:\", len(train_data))\n",
    "print(\"\\nValidation set size:\", len(validation_data))\n",
    "print(\"\\nTest set size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data as json-line file with current timestamp\n",
    "#timestamp = pd.Timestamp.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "#train_data.to_json(f\"data/length_train_data_ascii_{timestamp}.jsonl\", orient=\"records\", lines=True)\n",
    "#validation_data.to_json(f\"data/length_val_data_ascii_{timestamp}.jsonl\", orient=\"records\", lines=True)\n",
    "#test_data.to_json(f\"data/length_test_data_ascii_{timestamp}.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate hf-hub dataset and push to hf-hub\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(data, include_description=False):\n",
    "    # Reset the index\n",
    "    data = data.reset_index(drop=True)\n",
    "    # Ensure columns are strings\n",
    "    data['ascii_input'] = data['ascii_input'].astype(str)\n",
    "    data['Program'] = data['Program'].astype(str)\n",
    "\n",
    "    if include_description:\n",
    "        data['Description'] = data['Description'].astype(str)\n",
    "    \n",
    "    # Step 1: Create the new input column\n",
    "    if include_description:\n",
    "        data['Input'] = (\n",
    "            \"description: \" + data['Description'] +\n",
    "            \"ascii-art: \" + data['ascii_input'] \n",
    "        )\n",
    "    else:\n",
    "        data['Input'] = \"ascii-art: \" + data['ascii_input']\n",
    "        # optionally one could add start \"<s> \" and end tokens \" </s>\"\n",
    "\n",
    "    # Step 2: Drop unnecessary columns\n",
    "    data = data[['Input', 'Program']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c265bdf0ef214ee893c933010e44b1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491087a5e1eb4ab48987a8563f8d3894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0283ae3e2cd34e86900d9738904a0aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa2a0d556464e68a34e8ef2d712ae67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3c4da402f54a3a988db61ca4aaec92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d9af0fc2e44777ab192a814723ad81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe739ce263b41de8ae6b502dbfad631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458e7a13484449fcbdb52f2563717f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee40ca7f5da645caa6edc966693774e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea404b9a9444695835c12841950fbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933cd4cb4eb1431c80bbd393038d3146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74324237f3fe499cbb7b87347cfb0e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b742ce14fd3d448b8e22e095734398fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/527 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ruthchy/semantic-length-generalization-logo-data-ascii-desc/commit/30ee416a97395950587adfd7fc7c6f1cafe987bf', commit_message='Upload dataset', commit_description='', oid='30ee416a97395950587adfd7fc7c6f1cafe987bf', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/ruthchy/semantic-length-generalization-logo-data-ascii-desc', endpoint='https://huggingface.co', repo_type='dataset', repo_id='ruthchy/semantic-length-generalization-logo-data-ascii-desc'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(preprocess_dataset(train_data, include_description=False))\n",
    "validation_dataset = Dataset.from_pandas(preprocess_dataset(validation_data, include_description=False))\n",
    "test_dataset = Dataset.from_pandas(preprocess_dataset(test_data, include_description=False))\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "dataset_dict.push_to_hub(\"ruthchy/semantic-length-generalization-logo-data-ascii\", private=True)\n",
    "\n",
    "# Convert DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(preprocess_dataset(train_data, include_description=True))\n",
    "validation_dataset = Dataset.from_pandas(preprocess_dataset(validation_data, include_description=True))\n",
    "test_dataset = Dataset.from_pandas(preprocess_dataset(test_data, include_description=True))\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "dataset_dict.push_to_hub(\"ruthchy/semantic-length-generalization-logo-data-ascii-desc\", private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReGAL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
