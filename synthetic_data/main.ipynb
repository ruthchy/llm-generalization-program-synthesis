{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Synthetic Data with LOGO-Programs, Descriptions and the respective Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "from _1_logo_pseudo_code_generator import generateLOGOPseudoCode\n",
    "from _2_sampler import LOGOProgramSampler\n",
    "from _3_executable_logo_primitives import ReGALLOGOPrimitives\n",
    "from _4_logo_graphic_generator_v1 import PseudoProgramInterpreter as PseudoProgramInterpreter_v1\n",
    "from _4_logo_graphic_generator_v2 import PseudoProgramInterpreter as PseudoProgramInterpreter_v2\n",
    "from _5_ascii_processor import ASCIIProcessor\n",
    "\n",
    "generator=generateLOGOPseudoCode()\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the train and test data from the ReGAL-Paper. Join both and remove duplicate programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>8 sided snowflake with a short space and a sho...</td>\n",
       "      <td>for j in range(8):\\n    embed(\"\"\"penup()\\nforw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>8 sided snowflake with a medium triangle as arms</td>\n",
       "      <td>for j in range(8):\\n    embed(\"\"\"for i in rang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description  \\\n",
       "198  8 sided snowflake with a short space and a sho...   \n",
       "199   8 sided snowflake with a medium triangle as arms   \n",
       "\n",
       "                                               Program  \n",
       "198  for j in range(8):\\n    embed(\"\"\"penup()\\nforw...  \n",
       "199  for j in range(8):\\n    embed(\"\"\"for i in rang...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5 sided snowflake with a short line and a smal...</td>\n",
       "      <td>for j in range(5):\\n    embed(\"\"\"forward(4)\\nl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6 sided snowflake with a short space and a sho...</td>\n",
       "      <td>for j in range(6):\\n    embed(\"\"\"penup()\\nforw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Description  \\\n",
       "98  5 sided snowflake with a short line and a smal...   \n",
       "99  6 sided snowflake with a short space and a sho...   \n",
       "\n",
       "                                              Program  \n",
       "98  for j in range(5):\\n    embed(\"\"\"forward(4)\\nl...  \n",
       "99  for j in range(6):\\n    embed(\"\"\"penup()\\nforw...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>5 sided snowflake with a small 5 gon and a sma...</td>\n",
       "      <td>for j in range(5):\\n    embed(\"\"\"penup()\\nforw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6 sided snowflake with a small 5 gon and a sma...</td>\n",
       "      <td>for j in range(6):\\n    embed(\"\"\"penup()\\nforw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description  \\\n",
       "109  5 sided snowflake with a small 5 gon and a sma...   \n",
       "110  6 sided snowflake with a small 5 gon and a sma...   \n",
       "\n",
       "                                               Program  \n",
       "109  for j in range(5):\\n    embed(\"\"\"penup()\\nforw...  \n",
       "110  for j in range(6):\\n    embed(\"\"\"penup()\\nforw...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LOGO\n",
    "train_logo_data = \"logo_data/python/train_200_dataset.jsonl\"\n",
    "dev_logo_data = \"logo_data/python/dev_100.jsonl\"\n",
    "test_logo_data = \"logo_data/python/test_dataset.jsonl\"\n",
    "\n",
    "# Load train, dev and test dataset\n",
    "def load_data(data_path):\n",
    "    with open(data_path, 'r') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    return data\n",
    "\n",
    "# Extract descriptions and programs from train_data and transform into pandas DataFrame\n",
    "def extract_descriptions_and_programs(data):\n",
    "    extracted_data = []\n",
    "    for item in data:\n",
    "        description = None\n",
    "        program = None\n",
    "        if \"messages\" in item:  # suits the format for train_data and test_data\n",
    "            for message in item.get('messages', []):\n",
    "                if message['from'] == 'human':\n",
    "                    description = message['value']\n",
    "                elif message['from'] == 'gpt':\n",
    "                    program = message['value']\n",
    "        elif \"program\" in item and \"language\" in item: # suites the format for dev_data\n",
    "            program = item['program']\n",
    "            description = \" \".join(item['language'])\n",
    "\n",
    "        if description and program:\n",
    "            extracted_data.append([description, program])\n",
    "    extracted_data = pd.DataFrame(extracted_data, columns=['Description', 'Program'])\n",
    "    return extracted_data\n",
    "\n",
    "df_train = extract_descriptions_and_programs(load_data(f\"../external/dependencies/{train_logo_data}\"))\n",
    "df_dev = extract_descriptions_and_programs(load_data(f\"../external/dependencies/{dev_logo_data}\"))\n",
    "df_test = extract_descriptions_and_programs(load_data(f\"../external/dependencies/{test_logo_data}\"))\n",
    "\n",
    "display(df_train.tail(2))\n",
    "display(df_dev.tail(2))\n",
    "display(df_test.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the combined train and test data:  (311, 2)\n",
      "Dimensions of the combined train, dev and test data:  (411, 2)\n",
      "\n",
      "\n",
      "Dimensions of the combined train and test data without duplicate Programs:  (263, 2)\n",
      "Dimensions of the combined train, dev and test data without duplicate Programs:  (357, 2)\n"
     ]
    }
   ],
   "source": [
    "# Append the test data to the train data\n",
    "df_train_test = pd.concat([df_train, df_test], ignore_index=True)\n",
    "df_all = pd.concat([df_train, df_dev, df_test], ignore_index=True)\n",
    "print(\"Dimensions of the combined train and test data: \", df_train_test.shape)\n",
    "print(\"Dimensions of the combined train, dev and test data: \", df_all.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "#####################\n",
    "# Drop all duplicate rows\n",
    "df_train_test = df_train_test.drop_duplicates(subset=['Program']) # use the program as the unique identifier\n",
    "df_all = df_all.drop_duplicates(subset=['Program']) # use the program as the unique identifier\n",
    "#####################\n",
    "print(\"Dimensions of the combined train and test data without duplicate Programs: \", df_train_test.shape)\n",
    "print(\"Dimensions of the combined train, dev and test data without duplicate Programs: \", df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "54\n",
      "9643\n"
     ]
    }
   ],
   "source": [
    "print(311-263)\n",
    "print(411-357)\n",
    "print(10000-357)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Graphics for the ReGAL dataset and the Synthetic Data\n",
    "\n",
    "- initialize the sampler, if the train and test dataframes are porvided then the newly generated programs are not the same as the once in these datasets\n",
    "- the data can be stored in json-line format\n",
    "- next step is to initalize the interpreter, with this one can execute the programs and generate graphs\n",
    "    - the interpreter generates .png-files\n",
    "    - the size is for all graphics in one df the same (the aim is to keep size information which is relative to the other graphics thats why there can be a lot of whitespace this might be debatable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler=LOGOProgramSampler(generator, df_all) # this way only new programs are generated that are not in the train or test data\n",
    "\n",
    "# Synthetic data\n",
    "#synthetic_data = sampler.sample(9643) # sample 9643 new programs + the 357 programs from the train, dev and test data = 10000 programs\n",
    "#synthetic_data = pd.DataFrame(synthetic_data, columns=['Description', 'Program'])\n",
    "\n",
    "#save data as json-line file with current timestamp\n",
    "#timestamp = pd.Timestamp.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "#synthetic_data.to_json(f\"data/synthetic_data_{timestamp}.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "# load synthetic data\n",
    "synthetic_data = pd.read_json(\"data/synthetic_data_20250120143151.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate graphics for the synthetic data \n",
    "#interpreter = PseudoProgramInterpreter_v2()\n",
    "#interpreter.process_and_save_graphics(synthetic_data, output_dir=\"logo_graphic/synthetic_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = PseudoProgramInterpreter_v1()\n",
    "interpreter.process_and_save_graphics(synthetic_data, output_dir=\"logo_graphic/synthetic_v1\") # here graphics are thigthly cropped around the image\n",
    "# ca. 10.000 = 30 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 medium line in a row\n",
      "for j in range(7):\n",
      "    embed(\"\"\"forward(4)\"\"\", locals())\n",
      "    penup()\n",
      "    forward(2)\n",
      "    left(0.0)\n",
      "\n",
      "    pendown()\n",
      "connected sequence of shapes: a small 6-gon, a short line, a small 9-gon\n",
      "for i in range(6):\n",
      "    forward(2)\n",
      "    left(60.0)\n",
      "forward(2)\n",
      "for i in range(9):\n",
      "    forward(2)\n",
      "    left(40.0)\n"
     ]
    }
   ],
   "source": [
    "print(synthetic_data['Description'].iloc[4])\n",
    "print(synthetic_data['Program'].iloc[4])\n",
    "\n",
    "print(synthetic_data['Description'].iloc[9])\n",
    "print(synthetic_data['Program'].iloc[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST \n",
    "# create a test dataset form the all_data\n",
    "test_indices = [98, 44, 100, 99, 200, 212, 214, 201, 53, 54, 282] # examples representing different shapes and combinations for testing purposes\n",
    "df_test_subset = df_all.loc[test_indices].reset_index(drop=True)\n",
    "#display(df_test_subset)\n",
    "\n",
    "interpreter = PseudoProgramInterpreter_v2()\n",
    "interpreter.process_and_save_graphics(df_test_subset, output_dir=\"logo_graphic/11testshapes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReGAL DATA GRAPHICS\n",
    "interpreter = PseudoProgramInterpreter_v1()\n",
    "interpreter.process_and_save_graphics(df_all, output_dir=\"logo_graphic/all_ReGAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASCII-Transfromer\n",
    "\n",
    "based on the approach by Li and Ellis (2024). Similar to the authors  ensure a square image size (here 525x525) which I divied in 35x35 blocks with a pixel size of 15x15. In comparison the authors cropped a 512x512 section from the image around the center and divide it into 32x32 blocks with a pixel size of 16x16 each. Like the authors i then calculate the densty of black pixels and qunatizise this into 10 levels, which are represented by the ASCII numbers of 0-9. Each number represents a block resulting in a string with 35 lines, where each line has 35 numbers. A low density equals 0 and the higher the density of black pixels becomes the closer to 9 it will be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic data ASCII\n",
    "#processor = ASCIIProcessor(n_blocks=35, m_blocks=35, levels=10)\n",
    "\n",
    "dir_images = \"logo_graphic/synthetic_v1/\"\n",
    "synthetic_data_ascii = processor.store_ascii_input(synthetic_data, dir_images)\n",
    "display(synthetic_data_ascii.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "      <th>ascii_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 concentric square s</td>\n",
       "      <td>for i in range(5):\\n    embed(\"\"\"for j in rang...</td>\n",
       "      <td>00000000000000000000000000000000000\\n022222222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 sided snowflake with a medium line and a med...</td>\n",
       "      <td>for j in range(6):\\n    embed(\"\"\"forward(8)\\nl...</td>\n",
       "      <td>00000000000000000000100000000000000\\n000000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0                              4 concentric square s   \n",
       "1  6 sided snowflake with a medium line and a med...   \n",
       "\n",
       "                                             Program  \\\n",
       "0  for i in range(5):\\n    embed(\"\"\"for j in rang...   \n",
       "1  for j in range(6):\\n    embed(\"\"\"forward(8)\\nl...   \n",
       "\n",
       "                                         ascii_input  \n",
       "0  00000000000000000000000000000000000\\n022222222...  \n",
       "1  00000000000000000000100000000000000\\n000000000...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_images = \"logo_graphic/all_ReGAL/\"\n",
    "df_all_ascii = processor.store_ascii_input(df_all, dir_images)\n",
    "display(df_all_ascii.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Splits in Train and Test given generalization aspect\n",
    "\n",
    "- length generalization:\n",
    "    - criterion: semantic length\n",
    "- mix and match concepts\n",
    "    - compose different concepts\n",
    "    - switch concept order\n",
    "- apply general principles\n",
    "    - compose new operations\n",
    "    - add operation functunality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_syn = pd.concat([df_all_ascii, synthetic_data_ascii], ignore_index=True)\n",
    "len(df_all_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "9003\n",
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "      <th>ascii_input</th>\n",
       "      <th>Semantic Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a 5 pointed star</td>\n",
       "      <td>for i in range(5):\\n    forward(16)\\n    left(...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a greek spiral with 5 turns</td>\n",
       "      <td>for i in range(6):\\n    forward(1 * i)\\n    le...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Description  \\\n",
       "0             a 5 pointed star   \n",
       "1  a greek spiral with 5 turns   \n",
       "\n",
       "                                             Program  \\\n",
       "0  for i in range(5):\\n    forward(16)\\n    left(...   \n",
       "1  for i in range(6):\\n    forward(1 * i)\\n    le...   \n",
       "\n",
       "                                         ascii_input  Semantic Length  \n",
       "0  00000000000000000000000000000000000\\n000000000...                5  \n",
       "1  00000000000000000000000000000000000\\n000000000...                6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "      <th>ascii_input</th>\n",
       "      <th>Semantic Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9001</th>\n",
       "      <td>separated sequence of shapes: a small 7-gon, a...</td>\n",
       "      <td>for i in range(7):\\n    forward(2)\\n    left(5...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>1363362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9002</th>\n",
       "      <td>separated sequence of shapes: a small 7-gon, a...</td>\n",
       "      <td>for i in range(7):\\n    forward(2)\\n    left(5...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>1363362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Description  \\\n",
       "9001  separated sequence of shapes: a small 7-gon, a...   \n",
       "9002  separated sequence of shapes: a small 7-gon, a...   \n",
       "\n",
       "                                                Program  \\\n",
       "9001  for i in range(7):\\n    forward(2)\\n    left(5...   \n",
       "9002  for i in range(7):\\n    forward(2)\\n    left(5...   \n",
       "\n",
       "                                            ascii_input  Semantic Length  \n",
       "9001  00000000000000000000000000000000000\\n000000000...          1363362  \n",
       "9002  00000000000000000000000000000000000\\n000000000...          1363362  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "      <th>ascii_input</th>\n",
       "      <th>Semantic Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9003</th>\n",
       "      <td>a 3 sided snowflake with arms of connected seq...</td>\n",
       "      <td>for j in range(3):\\n    embed(\"\"\"for i in rang...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>1368450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9004</th>\n",
       "      <td>connected sequence of shapes: a small 7-gon, a...</td>\n",
       "      <td>for i in range(7):\\n    forward(2)\\n    left(5...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>1368451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Description  \\\n",
       "9003  a 3 sided snowflake with arms of connected seq...   \n",
       "9004  connected sequence of shapes: a small 7-gon, a...   \n",
       "\n",
       "                                                Program  \\\n",
       "9003  for j in range(3):\\n    embed(\"\"\"for i in rang...   \n",
       "9004  for i in range(7):\\n    forward(2)\\n    left(5...   \n",
       "\n",
       "                                            ascii_input  Semantic Length  \n",
       "9003  00000000000000000000000000000000000\\n000000000...          1368450  \n",
       "9004  00000000000000000000000000000000000\\n000000000...          1368451  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Program</th>\n",
       "      <th>ascii_input</th>\n",
       "      <th>Semantic Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>separated sequence of shapes: a small circle, ...</td>\n",
       "      <td>for i in range(HALF_INF):\\n    forward(EPS_DIS...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>68407622226360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>separated sequence of shapes: a small circle, ...</td>\n",
       "      <td>for i in range(HALF_INF):\\n    forward(EPS_DIS...</td>\n",
       "      <td>00000000000000000000000000000000000\\n000000000...</td>\n",
       "      <td>68408672018760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Description  \\\n",
       "9998  separated sequence of shapes: a small circle, ...   \n",
       "9999  separated sequence of shapes: a small circle, ...   \n",
       "\n",
       "                                                Program  \\\n",
       "9998  for i in range(HALF_INF):\\n    forward(EPS_DIS...   \n",
       "9999  for i in range(HALF_INF):\\n    forward(EPS_DIS...   \n",
       "\n",
       "                                            ascii_input  Semantic Length  \n",
       "9998  00000000000000000000000000000000000\\n000000000...   68407622226360  \n",
       "9999  00000000000000000000000000000000000\\n000000000...   68408672018760  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set size: 8006\n",
      "\n",
      "Validation set size: 997\n",
      "\n",
      "Test set size: 997\n"
     ]
    }
   ],
   "source": [
    "from _6_semantic_length import SemanticLength\n",
    "\n",
    "sem_length = SemanticLength()\n",
    "\n",
    "df_all_syn['Semantic Length'] = df_all_syn['Program'].apply(sem_length.calc_semantic_length)\n",
    "df_all_syn=df_all_syn.sort_values(by=\"Semantic Length\").reset_index(drop=True)\n",
    "\n",
    "# Determine the split index\n",
    "test_start_id = int(len(df_all_syn)*0.9)        # 10% for the test set\n",
    "print(test_start_id)\n",
    "# check and adjust the split index if both train and test contain programs with the same semantic length\n",
    "while (\n",
    "    test_start_id < len(df_all_syn) and \n",
    "    df_all_syn.loc[test_start_id, 'Semantic Length'] == df_all_syn.loc[test_start_id - 1, 'Semantic Length']\n",
    "):\n",
    "    test_start_id += 1\n",
    "print(test_start_id)\n",
    "\n",
    "# Create train and test splits\n",
    "train_data = df_all_syn.iloc[:test_start_id]\n",
    "test_data = df_all_syn.iloc[test_start_id:]\n",
    "\n",
    "print(\"Train:\")\n",
    "display(train_data.head(2))\n",
    "display(train_data.tail(2))\n",
    "print(\"\\nTest:\")\n",
    "display(test_data.head(2))\n",
    "display(test_data.tail(2))\n",
    "\n",
    "# Create a validation dataset from the training data about the same size as the test data\n",
    "rs = 42\n",
    "length = int(len(test_data))\n",
    "validation_data = train_data.sample(n=length, random_state=rs)  \n",
    "train_data = train_data.drop(validation_data.index)\n",
    "\n",
    "print(\"\\nTrain set size:\", len(train_data))\n",
    "print(\"\\nValidation set size:\", len(validation_data))\n",
    "print(\"\\nTest set size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data as json-line file with current timestamp\n",
    "#timestamp = pd.Timestamp.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "#train_data.to_json(f\"data/length_train_data_ascii_{timestamp}.jsonl\", orient=\"records\", lines=True)\n",
    "#validation_data.to_json(f\"data/length_val_data_ascii_{timestamp}.jsonl\", orient=\"records\", lines=True)\n",
    "#test_data.to_json(f\"data/length_test_data_ascii_{timestamp}.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate hf-hub dataset and push to hf-hub\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReGAL-prompt\n",
    "f\"\"\"\n",
    "Your task is to draw simple figures using python Turtle graphics.\\n\n",
    "You will use a custom turtle library, similar to the built-in library, which is sufficient for all tasks.\\n\n",
    "\\n\n",
    "Here's a description of the custom turtle library:\\n\n",
    "- forward(x): move forward x pixels\\n\n",
    "- left(theta): rotateleft by the theta a degrees\\n\n",
    "- right(theta): rotate right by the theta a degrees\\n\n",
    "- penup(): stop drawing\\n\n",
    "- pendown(): start drawing\\n\n",
    "- teleport(x, y, theta): move to position(x, y) with angle the theta\\n\n",
    "- heading(): get the current angle of the turtle\\n\n",
    "- isdown(): check if the pen is down\\n\n",
    "- embed(program, local vars): runs the code in program using the current context and teleports back to the original position. Allows you to next programs. Implementationally, embed gets the turtle state (is down, x, y, heading), executes program, then returns to the original state.\\n\n",
    "\\n\n",
    "You will be given a query and have to produce a program. Begin your program with a comment that explains your reasoning. For example, you might write:\\n\n",
    "# Thought: the query asks for a line, so I will use the forward() function.\\n\n",
    "Examples:\\n\n",
    "\\n\n",
    "Please generate ONLY the code to produce the answer and nothing else.\\n\n",
    "Query: Draw {description}\\n\n",
    "Program:\\n\n",
    "\"\"\"\n",
    "\n",
    "# PBE-prompt\n",
    "f\"\"\"\n",
    "Your task is to draw simple black and white graphics with the custom library. DO NOT USE THE BUILT-IN TURTLE LIBRARY.\\n\n",
    "You will use a custom turtle library, similar to the built-in library, which is sufficient for all tasks.\\n\n",
    "\\n\n",
    "Here are all the available functions in the custom turtle library:\\n\n",
    "- forward(x): move forward x pixels\\n\n",
    "- left(theta): rotate left by theta degrees\\n\n",
    "- right(theta): rotate right by theta degrees\\n\n",
    "- penup(): stop drawing\\n\n",
    "- pendown(): start drawing\\n\n",
    "- teleport(x, y, theta): move to position (x, y) with angle theta\\n\n",
    "- heading(): get the current angle of the turtle\\n\n",
    "- isdown(): check if the pen is down\\n\n",
    "- embed(program, local vars): runs the code in program using the current context and teleports back to the original position. Allows you to nest programs. Implementationally, embed gets the turtle state (is down, x, y, heading), executes program, then returns to the original state.\\n\n",
    "\\n\n",
    "Graphic:\n",
    "Python program: draw an interesting graphic using our own custom turtle library.\\n\n",
    "# the following program draws {description}:\\n\n",
    "Program: {program}\\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my prompt template based on the ReGAL and PBE prompt-templates\n",
    "sys_prompt = \"\"\"<sys_prompt>\\n\n",
    "Your task is to draw simple black and white graphics with the custom library. DO NOT USE THE BUILT-IN TURTLE LIBRARY.\\n\n",
    "You will use a custom turtle library, similar to the built-in library, which is sufficient for all tasks.\\n\n",
    "</sys_prompt>\\n\"\"\"\n",
    "\n",
    "custom_library_desc = \"\"\"<custom_library_desc>\\n\n",
    "Here are all the available functions in the custom turtle library:\\n\n",
    "- forward(x): move forward x pixels\\n\n",
    "- left(theta): rotate left by theta degrees\\n\n",
    "- right(theta): rotate right by theta degrees\\n\n",
    "- penup(): stop drawing\\n\n",
    "- pendown(): start drawing\\n\n",
    "- teleport(x, y, theta): move to position (x, y) with angle theta\\n\n",
    "- heading(): get the current angle of the turtle\\n\n",
    "- isdown(): check if the pen is down\\n\n",
    "- embed(program, local vars): runs the code in program using the current context and teleports back to the original position. Allows you to nest programs. Implementationally, embed gets the turtle state (is down, x, y, heading), executes program, then returns to the original state.\\n\n",
    "</custom_library_desc>\\n\"\"\"\n",
    "\n",
    "task = \"\"\"<task>\\n\n",
    "Use the following description and ascii-art representing the target graphic to generate the python program:\\n\n",
    "</task>\\n\"\"\"\n",
    "\n",
    "output_template = \"\"\"<output>\\n\n",
    "Please generate only the code to produce the answer and nothing else.\\n\n",
    "    Program: \\n\n",
    "</output>\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_template(description, ascii_input, program, include_description=False, include_ascii=False):\n",
    "    if include_description and include_ascii:\n",
    "        prompt = sys_prompt + \"\\n\" + custom_library_desc + \"\\n\" + task + \"\\n\" + f\"    <s>Description: {description}\\n    ASCII-Art:\\n{ascii_input}</s>\\n\" + \"\\n\" + output_template\n",
    "        \n",
    "    elif include_description:\n",
    "        prompt = sys_prompt + \"\\n\" + custom_library_desc + \"\\n\" + task + \"\\n\" + f\"    <s>Description: {description}</s>\\n\" + \"\\n\" + output_template\n",
    "    \n",
    "    elif include_ascii:\n",
    "        prompt = sys_prompt + \"\\n\" + custom_library_desc + \"\\n\" + task + \"\\n\" + f\"    <s>ASCII-Art:\\n{ascii_input}</s>\\n\" + \"\\n\" + output_template\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"At least one of include_description or include_ascii must be True.\")\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(data, include_description=False, include_ascii=False):\n",
    "    # Reset the index\n",
    "    data = data.reset_index(drop=True)\n",
    "    # Ensure columns are strings\n",
    "    data['ascii_input'] = data['ascii_input'].astype(str)\n",
    "    data['Program'] = data['Program'].astype(str)\n",
    "\n",
    "    if include_description:\n",
    "        data['Description'] = data['Description'].astype(str)\n",
    "    \n",
    "    # Create the prompt\n",
    "    data['Input'] = data.apply(lambda x: prompt_template(x['Description'], x['ascii_input'], x['Program'], include_description, include_ascii), axis=1)\n",
    "\n",
    "    data = data[['Input', 'Program']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(data, include_description=False):\n",
    "    # Reset the index\n",
    "    data = data.reset_index(drop=True)\n",
    "    # Ensure columns are strings\n",
    "    data['ascii_input'] = data['ascii_input'].astype(str)\n",
    "    data['Program'] = data['Program'].astype(str)\n",
    "\n",
    "    if include_description:\n",
    "        data['Description'] = data['Description'].astype(str)\n",
    "    \n",
    "    # Step 1: Create the new input column\n",
    "    if include_description:\n",
    "        data['Input'] = (\n",
    "            \"description: \" + data['Description'] +\n",
    "            \"ascii-art: \" + data['ascii_input'] \n",
    "        )\n",
    "    else:\n",
    "        data['Input'] = \"ascii-art: \" + data['ascii_input']\n",
    "        # optionally one could add start \"<s> \" and end tokens \" </s>\"\n",
    "    \n",
    "    # Step 2: Drop unnecessary columns\n",
    "    data = data[['Input', 'Program']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9191ae09f19e40909ba8c845a8f0b4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a729d06765534614ad938382d953074c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ecdd0fad6c4b339d700894253ed6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc413074a3b44b8ab86e43cd964baeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45fe5a8970a4a9299c46d8dc2e98f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a75262911dd45a6930adb013bec6665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9d57e4a1004602a5922573dd5259ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/527 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874fd2d596df4f24826d05173b83afa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54bb45258c984f87b1a2666a14d79a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f885212acd1b4cdd8dabc48e2df0d45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4c5a39d4ec4209887f6fef5f0746c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2637746a544177a7e41e7a09f1a602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408cf9c634b641c4a36ad98a9a993c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f16a6e380c4f12a3dd78f2f7e58463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/527 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547c895c82f94cab80e193491fb14703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da46177001bd49d2b4ac977cf2d75014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9b5461cf2c4d5da5a828f92a55f258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b283c0eba827464ab946ae0fe9c92697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76d566805f9462fb8536fbbc9b4ee10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81e21df265f41f0b93d83fe70c25a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4b414e9d6445b6b024995d769c1b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/527 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ruthchy/semantic-length-generalization-logo-data-ascii-desc/commit/567c240b3909c0db503197f8ec5c5425fdf9e9b3', commit_message='Upload dataset', commit_description='', oid='567c240b3909c0db503197f8ec5c5425fdf9e9b3', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/ruthchy/semantic-length-generalization-logo-data-ascii-desc', endpoint='https://huggingface.co', repo_type='dataset', repo_id='ruthchy/semantic-length-generalization-logo-data-ascii-desc'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(preprocess_dataset(train_data, include_description=False, include_ascii=True))\n",
    "validation_dataset = Dataset.from_pandas(preprocess_dataset(validation_data, include_description=False, include_ascii=True))\n",
    "test_dataset = Dataset.from_pandas(preprocess_dataset(test_data, include_description=False, include_ascii=True))\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "dataset_dict.push_to_hub(\"ruthchy/semantic-length-generalization-logo-data-ascii\", private=False)\n",
    "\n",
    "# Convert DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(preprocess_dataset(train_data, include_description=True, include_ascii=False))\n",
    "validation_dataset = Dataset.from_pandas(preprocess_dataset(validation_data, include_description=True, include_ascii=False))\n",
    "test_dataset = Dataset.from_pandas(preprocess_dataset(test_data, include_description=True, include_ascii=False))\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "dataset_dict.push_to_hub(\"ruthchy/semantic-length-generalization-logo-data-desc\", private=False)\n",
    "\n",
    "# Convert DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(preprocess_dataset(train_data, include_description=True, include_ascii=True))\n",
    "validation_dataset = Dataset.from_pandas(preprocess_dataset(validation_data, include_description=True, include_ascii=True))\n",
    "test_dataset = Dataset.from_pandas(preprocess_dataset(test_data, include_description=True, include_ascii=True))\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "dataset_dict.push_to_hub(\"ruthchy/semantic-length-generalization-logo-data-ascii-desc\", private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Input from the train dataset:\n",
      "<sys_prompt>\n",
      "\n",
      "Your task is to draw simple black and white graphics with the custom library. DO NOT USE THE BUILT-IN TURTLE LIBRARY.\n",
      "\n",
      "You will use a custom turtle library, similar to the built-in library, which is sufficient for all tasks.\n",
      "\n",
      "</sys_prompt>\n",
      "\n",
      "<custom_library_desc>\n",
      "\n",
      "Here are all the available functions in the custom turtle library:\n",
      "\n",
      "- forward(x): move forward x pixels\n",
      "\n",
      "- left(theta): rotate left by theta degrees\n",
      "\n",
      "- right(theta): rotate right by theta degrees\n",
      "\n",
      "- penup(): stop drawing\n",
      "\n",
      "- pendown(): start drawing\n",
      "\n",
      "- teleport(x, y, theta): move to position (x, y) with angle theta\n",
      "\n",
      "- heading(): get the current angle of the turtle\n",
      "\n",
      "- isdown(): check if the pen is down\n",
      "\n",
      "- embed(program, local vars): runs the code in program using the current context and teleports back to the original position. Allows you to nest programs. Implementationally, embed gets the turtle state (is down, x, y, heading), executes program, then returns to the original state.\n",
      "\n",
      "</custom_library_desc>\n",
      "\n",
      "<task>\n",
      "\n",
      "Use the following description and ascii-art representing the target graphic to generate the python program:\n",
      "\n",
      "</task>\n",
      "\n",
      "    <s>Description: a greek spiral with 6 turns\n",
      "    ASCII-Art:\n",
      "00000000000000000000000000000000000\n",
      "00000000000000000000000000000000000\n",
      "00000000000000000000000000000000000\n",
      "00000000000000000000000000000000000\n",
      "00222222222222222222222222222222220\n",
      "00000000000000000000000000000000020\n",
      "00000000000000000000000000000000020\n",
      "00000000000000000000000000000000020\n",
      "00000000000000000000000000000000020\n",
      "00000000000000000000000000000000020\n",
      "00000000000000000000000000000000020\n",
      "00000000000000000000000000000000020\n",
      "00000000000000000000000000000000020\n",
      "00000000000000000000000000000000020\n",
      "00000000000012222222221000000000020\n",
      "00000000000020000000002000000000020\n",
      "00000000000020000000002000000000020\n",
      "00000000000020000000002000000000020\n",
      "00000000000020000000002000000000020\n",
      "00000000000020000000002000000000020\n",
      "00000000000020000000000000000000020\n",
      "00000000000020000000000000000000020\n",
      "00000000000020000000000000000000020\n",
      "00000000000020000000000000000000020\n",
      "00000000000020000000000000000000020\n",
      "00000000000020000000000000000000020\n",
      "00000000000020000000000000000000020\n",
      "00000000000020000000000000000000020\n",
      "00000000000020000000000000000000020\n",
      "00000000000020000000000000000000020\n",
      "00000000000032222222222222222222220\n",
      "00000000000000000000000000000000000\n",
      "00000000000000000000000000000000000\n",
      "00000000000000000000000000000000000\n",
      "00000000000000000000000000000000000</s>\n",
      "\n",
      "<output>\n",
      "\n",
      "Please generate only the code to produce the answer and nothing else.\n",
      "\n",
      "    Program: \n",
      "\n",
      "</output>\n",
      "\n",
      "\n",
      "First Program from the test dataset:\n",
      "for j in range(7):\n",
      "    embed(\"\"\"for i in range(3):\n",
      "    forward(2)\n",
      "    left(120.0)\n",
      "forward(2)\n",
      "left(180)\n",
      "for i in range(HALF_INF):\n",
      "    forward(EPS_DIST*2)\n",
      "    left(EPS_ANGLE)\n",
      "for i in range(HALF_INF):\n",
      "    forward(EPS_DIST*2)\n",
      "    left(EPS_ANGLE)\"\"\", locals())\n",
      "    forward(0)\n",
      "    left(51.42857142857143)\n"
     ]
    }
   ],
   "source": [
    "# Printing just the 'Input' (description and ASCII art) of the first row in the train dataset\n",
    "print(\"First Input from the train dataset:\")\n",
    "print(dataset_dict[\"train\"][2][\"Input\"])\n",
    "\n",
    "# Printing just the 'Program' of the first row in the test dataset\n",
    "print(\"\\nFirst Program from the test dataset:\")\n",
    "print(dataset_dict[\"test\"][2][\"Program\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReGAL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
